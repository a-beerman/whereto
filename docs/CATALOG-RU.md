# Каталог (RU): архитектура, модель данных и ingestion

## 1. Цель

Сформировать **канонический офлайн-каталог** заведений (venues) в нашей БД, синхронизируя данные из внешних источников (на старте — **Google Places**) и обслуживая все пользовательские чтения из нашей базы.

### Источники данных

**Основной источник (Фаза 1)**:
- **Google Places API** — первичный источник данных о заведениях

**Дополнительные источники (опционально)**:
- **Парсинг сайтов доставки** — для получения актуальных данных о меню, ценах, наличии
- **Интеграция с собственной ERP** — для заведений, которые уже используют нашу систему

Архитектура поддерживает множественные источники через абстракцию `VenueSource`, что позволяет добавлять новые источники без изменения основной логики. См. [`docs/TZ-RU.md`](TZ-RU.md) Раздел 3.2 и [`docs/FINAL-SPEC.md`](FINAL-SPEC.md) Раздел 2.

## 2. Высокоуровневая архитектура

Компоненты:

- **Ingestion Job** (batch/cron/queue worker): запускается **на город** и синкает данные из источников (Google Places, сайты доставки, ERP).
- **API**: читает каталог только из нашей БД (поиск/карточки).
- **DB**: хранит нормализованные сущности + источники + overrides.

Поток данных:

1) Планировщик запускает job для `City` (например, ежедневно/каждые N часов).
2) Job забирает данные из источников (Google Places по границам/радиусу/категориям, парсинг сайтов доставки, интеграция с ERP).
3) Нормализует данные из разных источников в единую модель.
4) Пишет/обновляет сущности `Venue` + `VenueSource` (с указанием источника).
5) Применяет `VenueOverrides` (ручные правки) поверх синхронизированных данных.
6) API использует итоговый «проекционный» вид при выдаче.

## 3. Доменная модель (минимальная)

### City

Справочник городов/локаций, на которые делаем ingestion.

Минимальные поля:

- `id`
- `name`
- `country_code`
- `center_lat`, `center_lng`
- `bounds` (опционально, bbox/полигон)
- `timezone`
- `is_active`

### Venue

Каноническая запись заведения в нашей БД.

Минимальные поля:

- `id`
- `city_id`
- `name`
- `address`
- `lat`, `lng`
- `categories` (наши нормализованные категории/теги)
- `rating`, `rating_count` (если доступно)
- `photo_refs` (ссылки/идентификаторы)
- `hours` (структура/строка)
- `status` (`active` / `hidden` / `duplicate`)
- `created_at`, `updated_at`

Принцип: `Venue` — это то, что мы показываем пользователю.

### VenueSource

Связка «канонический Venue ⇄ запись во внешнем источнике».

Назначение:

- хранить идентификаторы источника (например, Google `place_id`, ID из ERP, URL сайта доставки)
- отслеживать время последнего синка и сырой payload (опционально)
- позволить подключать другие источники позже
- поддерживать множественные источники для одного venue (например, Google Places + сайт доставки)

Минимальные поля:

- `id`
- `venue_id`
- `source` (например, `google_places`, `delivery_site`, `erp`)
- `external_id` (например, Google `place_id`, ID из ERP, URL)
- `last_synced_at`
- `raw_hash` (хэш нормализованного payload для детекта изменений)

**Поддерживаемые источники**:
- `google_places` — основной источник (Фаза 1)
- `delivery_site` — парсинг сайтов доставки (опционально)
- `erp` — интеграция с собственной ERP (опционально)

### VenueOverrides

Ручные правки/курирование, которые должны переживать последующие синки.

Примеры полей:

- `venue_id`
- `name_override`
- `address_override`
- `pin_override` (lat/lng)
- `category_overrides`
- `hidden` (bool)
- `note` (для редактора)
- `updated_by`, `updated_at`

Принцип: при выдаче/проекции применяем overrides поверх полей `Venue`.

## 4. Ingestion по городу

### Гранулярность

- единица запуска — **City**
- внутри job могут быть подзадачи по категориям/сегментам

### Псевдо-алгоритм

1) Получить конфиг города (bounds/центр/радиус), список категорий, список активных источников.
2) Для каждого активного источника:
   - **Google Places**: для каждой категории запросить Places API (pagination), нормализовать записи
   - **Сайты доставки**: парсить страницы заведений, извлекать данные (меню, цены, наличие), нормализовать
   - **ERP**: запросить API ERP, получить данные о заведениях, нормализовать
3) Для каждой нормализованной записи:
   - найти `VenueSource` по `(source, external_id)`
   - если найден → обновить связанный `Venue` (объединить данные из разных источников, если venue уже существует)
   - если не найден → создать `Venue` и `VenueSource`
4) Запустить дедупликацию, пометить дубли (учитывая данные из всех источников).
5) Обновить `last_synced_at` для каждого источника, сохранить метрики.

## 5. Дедупликация (rules)

Цель — не плодить одинаковые заведения из разных запросов/категорий.

Рекомендуемые правила (в порядке приоритета):

1) **Source ID**: одинаковый `external_id` в рамках одного `source` = тот же venue.
2) **Geo + name**: если расстояние < X метров (например, 30–60м) и `name` очень похож (нормализованный), то вероятный дубль.
3) **Address match**: совпадает нормализованный адрес + похожее имя.

Действия при дубле:

- выбрать «master venue» (например, с более полным набором полей/фото)
- второй пометить как `duplicate/hidden`
- хранить связь/причину (если нужно, отдельной таблицей)

## 6. Кэширование и выдача

Принципы:

- API читает из БД; внешний API не зовём в пользовательском запросе.
- Поиск может использовать:
  - гео-индексы (PostGIS)
  - полнотекст (tsvector) / отдельный search индекс

Кэширование:

- кэшировать «популярные запросы» на уровне API (short TTL)
- кэшировать карточку venue (short TTL)

## 7. Частота обновлений (cadence)

Рекомендуемый режим для MVP:

- **Полный синк города**: 1 раз в сутки (ночью по локальному времени)
- **Инкрементальные обновления**: каждые 2–6 часов (если поддерживается по изменениям/хэшам)
- **Ручной ресинк**: по кнопке/команде для оператора

Выбор cadence зависит от стоимости Google Places и важности свежести.

## 8. Наблюдаемость и качество

Логи/метрики job:

- длительность синка на город
- количество полученных записей
- количество созданных/обновлённых `Venue`
- количество дублей
- ошибки/ретраи

Качество данных:

- coverage по категориям
- freshness
- override rate

